# -*- coding: utf-8 -*-
"""CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qg-vqhy844-8xmfLgdnkuU9NCWjis2ks

## IMPORT PART
"""

import random as r
import numpy as np
import pandas as pd
import math as m
import dataloader as load
from pathlib import Path
import matplotlib.pyplot as plt



"""## DEF PART"""

# ReLu
def relu(x):
    return np.maximum(0, x)


# derivative of ReLU
def derivative(x):
    return x > 0


# histogram(전처리)
def histogram(img):
    img256 = np.round(img * 255)

    histo, bin = np.histogram(img256, 784, [0, 256])

    cdf = histo.cumsum()
    # imgshow(img256)

    cdf = (cdf - cdf.min()) * 256 / (cdf.max() - cdf.min())

    img = cdf[img256.astype(int)]
    img = img / 255

    return img


# test
def imgshow(image):
    for i in range(28):
        for j in range(28):
            print('{:3}'.format(round(image[i * 28 + j])), end="  ")
        print("")


# cross entropy
def ce(lst1, lst2):
    value = np.max(lst1 * lst2)
    # print(lst1)
    # print(value)
    return -np.log(value)


# softmax ( 안정 )
def softmax(lst):
    maximum = np.max(lst)
    expo = np.exp(lst - maximum)
    sum = np.sum(expo)
    return expo / sum

# 흠..
def confu(lst):
  for i in range(10):
    sum = np.sum(lst[i])
    lst[i]=lst[i]/sum
  return 0

def linforward(ilayer, iweight):
    return np.dot(ilayer, iweight)


def reluforward(ilayer):
    return relu(ilayer)


def linbackward(ilayer, iweight, ograd):
    yield np.dot(ograd, iweight.T)
    yield np.dot(np.array([ilayer]), ograd.T)


def relubackward(ilayer, ograd):
    grad = ilayer > 0
    return grad * ograd

# data 불러오기, data size는 28*28!
    batch_size = 1
    suffle = True
    traindata = load.Dataloader(Path.cwd(), True, batch_size, suffle)
    trainsize = len(traindata)
    # print(trainsize)
    testdata = load.Dataloader(Path.cwd(), False, batch_size, suffle)
    testsize = len(testdata)

"""##CNN DEF"""

def zeropad(imgs,size):
  return np.pad(imgs,((0,0),(size,size),(size,size)),'constant', constant_values=0) 

#convolution
def im2col(imgs, ksize, stride=1):
  c, n, n = np.shape(imgs)
  padimg = zeropad(imgs,ksize//2)
  on = int(n/stride)
  col = np.zeros((c,ksize,ksize,on,on))
  for i in range(ksize):
    for j in range(ksize):
      col[:,i,j,:,:]=padimg[:,i:i+n:stride,j:j+n:stride]
  retcol = col.transpose(0,3,4,1,2).reshape(c*on*on,ksize*ksize)
  return retcol

def convolution(imgs, kernals, stride = 1):
  #print(np.shape(imgs),np.shape(kernals),"img, kernals")
  channel=np.shape(imgs)[0]
  isize=np.shape(imgs)[1]
  knumber=np.shape(kernals)[1]
  ksize=np.shape(kernals)[2]
  col=im2col(imgs,ksize,stride)
  #print(np.shape(col),"col")
  dotker=kernals.reshape(knumber,-1).T
  #print(np.shape(dotker),"dotker")
  #print(np.shape(col),np.shape(dotker),"col and dotker")
  return np.dot(col,dotker).reshape((channel,isize//stride, isize//stride,-1)).transpose(0,3,1,2)

"""
def convolution(img, kernal,stride=1):
  imgsize=np.shape(img)[0]
  kernalsize=np.shape(kernal)[0]
  padimg=zeropad(img,kernalsize//2)
  retimg=np.zeros((imgsize//stride,imgsize//stride))
  i=0
  kerline=kernal.reshape((kernalsize*kernalsize))
  while i<imgsize:
    j=0
    while j<imgsize:
      temp=padimg[i:i+kernalsize, j : j+kernalsize].reshape((kernalsize*kernalsize))
      retimg[i][j]=np.convolve(temp,kerline,'valid')
      j+=stride
    i+=stride
  print("conv end!")
  return retimg
"""
##Maxpool은 pool한 값과 그 위치를 기억해야 함


def Maxpool(img,stride=2):
  n=np.shape(img)[0]
  m=int(n/stride)
  img2=img.reshape(m,stride,m,stride)
  return np.max(img2,axis=(1,3))

def Maxpools(imgs, stride = 2):
  n = np.shape(imgs)[0]
  m = np.shape(imgs)[1]
  size = np.shape(imgs)[2]
  nsize=int(size//stride)
  retimgs = np.zeros((n,m,nsize,nsize))
  for i in range(n):
    for j in range(m):
      retimgs[i][j]=Maxpool(imgs[i][j],stride)
  return retimgs

"""##Lin Class"""

class lin:
    def __init__(self, isize, osize, alpha=0.1):
        """
        s = m.sqrt(2/isize)
        n = np.random.randn(isize,osize)
        self.weights = n*s
        """
        self.weights = np.random.normal(0, m.sqrt(2 / isize), (isize, osize))
        # self.weights = (np.random.rand(isize, osize)-0.5)/isize*2
        # self.weights = np.random.uniform(-m.sqrt(6/isize),m.sqrt(6/isize), (isize, osize))
        self.lrate = alpha
        self.bias = np.zeros(osize) / isize

    def forward(self, inp, dropout=0.5):
        # return np.dot(inp,self.weights)
        if dropout == 0:
            return np.dot(inp, self.weights) 
        m, n = np.shape(self.weights)
        temp = np.random.rand(m, n)
        temp2 = temp > dropout
        # print(np.shape(temp2))
        # print(temp2.reshape(784*400))

        temp2 = temp2 * self.weights * (1 / (1 - dropout))
        return np.dot(inp, temp2) + self.bias

    def backward(self, inp, ograd):
        # print(np.shape(inp), "inp",  np.shape(ograd), "ograd", np.shape(self.weights), "weights")
        igrad = np.dot(ograd, self.weights.T)
        wgrad = np.dot(np.array([inp]).T, ograd)
        # print(np.shape(wgrad))
        self.weights -= self.lrate * wgrad
        return igrad

"""##Conv Class"""

class Conv:
    def __init__(self, isize,ichannel ,ksize, knumber,pool=2, alpha=0.1):
        """
        s = m.sqrt(2/isize)
        n = np.random.randn(isize,osize)
        self.weights = n*s
        """
        self.isize = isize
        self.ichannel = ichannel
        self.ksize = ksize
        self.knumber = knumber
        self.weights = np.random.normal(0, m.sqrt(2 / (isize*isize*ichannel)), (1, knumber, ksize, ksize))
        self.convd = np.zeros((ichannel, knumber,isize,isize))
        self.relud = np.zeros((ichannel, knumber,isize, isize))
        self.pooled = np.zeros((ichannel, knumber,int(isize//pool),int(isize//pool)))
        self.pool = pool
        # self.weights = (np.random.rand(isize, osize)-0.5)/isize*2
        # self.weights = np.random.uniform(-m.sqrt(6/isize),m.sqrt(6/isize), (isize, osize))
        self.lrate = alpha
        #self.bias = np.zeros(osize) / isize

    def conv(self, inp):
        # return np.dot(inp,self.weights)
        ##convolution part
        #print(np.shape(self.weights))
        self.convd = convolution(inp, self.weights, 1)
        return 0
        """
        retnp = np.zeros((self.knumber,self.isize,self.isize))
        for k in range(self.knumber):
          for i in range(self.ichannel):
            retnp[k]=retnp[k]+convolution(inp[i],self.weights[i][k])
            #retnp[k]=np.sum(retnp[k], convolution(inp[i],self.weights[i][k]))
        ## RELU part
        self.convd=retnp
        return 0
        """

    def relu(self, inp):
      self.relud=relu(inp)
      return 0
    
    def Pool(self,inp):
        poolret=np.zeros((self.knumber,self.isize//self.pool, self.isize//self.pool))
        ## Maxpooling part
        """
        for k in range(self.knumber):
          poolret[k]=Maxpool(inp[k],self.pool)
        self.pooled=poolret
        """
        self.pooled=Maxpools(inp,self.pool)
        #print(np.shape(self.pooled))
        #print(0/0)
        return 0

    def forward(self,inp):
      self.conv(inp)
      self.relu(self.convd)
      self.Pool(self.relud)
      #print(np.shape(self.convd),np.shape(self.relud),np.shape(self.pooled))
      return 0

    def MaxBack(self, inp, argret, pool, orgad):
      n = np.shape(inp)[0]
      igrad=0
      for i in range(n):
        inp[i]
      return igrad


    def ConvBack(self, inp, ograd):
        #print(np.shape(inp), "inp",  np.shape(ograd), "ograd", np.shape(self.weights), "weights")
        ograd=ograd.reshape(28,28)
        inp=inp.reshape(28,28)
        filt=self.weights.reshape(9,9)
        igrad = np.zeros(np.shape(inp))
        wgrad = np.zeros(np.shape(self.weights))
        filtersize = np.shape(self.weights)[2]
        i=0
        while (i+filtersize)<28:
          j=0
          while (j+filtersize)<28:
            wgrad += inp[i:i+filtersize, j:j+filtersize] *ograd[i][j]
            igrad[i:i+filtersize, j:j+filtersize] += ograd[i][j]*filt
            j+=1
          i+=1
        self.weights-=self.lrate*wgrad.reshape(1,1,9,9)
        
        return ograd

"""## CNN Class"""

class CNN:
    def __init__(self, k1size,k1number,k2size,k2number,pool1=2,pool2=7, alpha=0.1):
        self.cl1 = Conv(28,1,k1size,k1number,pool1,alpha)
        self.cl2 = Conv(int(28//pool1),k1number,k2size,k2number,pool2,alpha)
        self.lin = lin(int(k1number*k2number*28*28/pool1/pool2/pool1/pool2),10,alpha)

        self.softmax = np.zeros(10)
        self.ograd = np.zeros(10)
        self.k1num = k1number
        self.k2num = k2number
        self.pool1=pool1
        self.pool2=pool2
        self.ol=np.zeros(10)
        self.lined = np.zeros(int((28*28/self.pool1/self.pool1/self.pool2/self.pool2*self.k1num*self.k2num)))

    def forward(self, input, dropout=0.5):

        self.cl1.forward(input)

        self.cl2.forward(self.cl1.pooled.reshape(self.k1num,int(28/self.pool1),int(28/self.pool1)))

        self.lined = self.cl2.pooled.reshape(int((28*28/self.pool1/self.pool1/self.pool2/self.pool2*self.k1num*self.k2num)))

        self.ol = self.lin.forward(self.lined)

        self.softmax = softmax(self.ol)
        return self.softmax

    def calograd(self, ans):
        self.ograd = self.softmax - ans
        return 0

    def backward(self):
        temp = self.ograd
        # print(np.shape(self.ograd))
        """
        self.ograd = self.tw.firstback(self.ograd, self.tlr)
        self.ograd = relubackward(self.tlr, self.ograd)

        self.ograd = np.dot(self.ograd.T, temp.T).T
        #print(np.shape(self.ograd))
        """
        self.ograd = self.lin.backward(self.lined, self.ograd)

        a, b, c, d = np.shape(self.cl2.pooled)
        self.ograd = self.ograd.reshape((a,b,c,d))

        self.ograd = relubackward(self.cl2.pooled, self.ograd)

        self.ograd = self.cl2.ConvBack(self.cl1.pooled,self.ograd)


    def train(self, image, label):
        pass

    # for image 1
    def train_and_test(self, traini, trainl, testi, testl, dropout=0):
        testloss = 0
        trainloss = ce(self.forward(traini, dropout), trainl)
        self.calograd(trainl)
        self.backward()

        testloss = ce(self.forward(testi, dropout), testl)

        return (trainloss, testloss)

    # for image 2, 3
    def test(self, testi, testl, matrix, topthree, topthreeimg):
        sm =self.forward(testi, dropout=0)
        crossentropy = ce(sm, testl)
        predict = np.argmax(sm)
        real = np.argmax(testl)
        if predict == real:
          amax = np.argmin(topthree[predict])
          if topthree[predict][amax] < sm[predict]:
            topthree[predict][amax] = sm[predict]
            topthreeimg[predict][amax] = testi
        matrix[real][predict] += 1

"""## HYPERPARAMETER PART"""

# layer size
    k1size = 9
    k1number = 1
    k2size = 9
    k2number = 1
    pool1 = 1
    pool2 = 1
    # 784 400 300 ->70%

    # alpha = learning rate
    alpha = 0.02

    # batch_size
    batch_size = 1

    # epoch
    epoch = 2
    # suffle?
    suffle = True

    # NN DataSet
    NeuralNet = CNN(k1size,k1number,k2size,k2number,pool1,pool2, alpha)



    # 실험용으로만..

    # test용 data section
 

    print("epoch: %d, learning rate: %f" % (epoch, alpha))

"""## CNN DEFS TEST"""

trainimage, trainlabel = traindata[0]
trainimage=trainimage.reshape(28,28)

"""## TRAIN PART"""

trainloss=[]
testloss=[]
for i in range(epoch):
  corcount = 0
  wrongcount = 0
  lossinepoch = 0
  count = 0
  cross = 0
  tcross = 0
  for trainimage, trainlabel in traindata:
    img = trainimage.reshape(1,28,28)
    sm = NeuralNet.forward(img, dropout=0)
    loss = ce(sm, trainlabel)
    cross+=loss
    #print(loss)
    count+=1
    if np.argmax(sm) == np.argmax(trainlabel):
        corcount += 1
    else:
        wrongcount +=1
    #print(corcount/wrongcount)
    NeuralNet.calograd(trainlabel)
    NeuralNet.backward()
    if count % 600 == 0:
        print(count/600, "%, current accuracy is ", '{:5}'.format(corcount/(wrongcount+corcount)*100)," %")
        #print(NeuralNet.sw.weights.reshape(hlsize*olsize)*hlsize)
        #print(NeuralNet.tw.weights.reshape(olsize*10)*olsize)
  for testimage, testlabel in testdata:
    img = testimage.reshape(1,28,28)
    img = histogram(img)
    sm = NeuralNet.forward(img, dropout=0)
    tcross += ce(sm, testlabel)
  trainloss.append(cross/60000)
  testloss.append(tcross/10000)
  print(i + 1, "epoch ended, current accuracy is ", corcount / 60000, "\n","avg. trainloss is ", cross / 60000 , "\n", "avg.testloss is", tcross/10000)

for testimage, testlabel in testdata:
    img = testimage.reshape(1,28,28)
    img = histogram(img)
    sm = NeuralNet.forward(img, dropout=0)

"""##IMAGE"""

t = np.arange(0, epoch, 1)
print(trainloss, testloss)
plt.subplots_adjust(left=0.125, bottom=-0.5, right=0.9, top=0.9, wspace=0.2, hspace=0.2)
plt.subplot(3,1,1)
plt.plot(t, trainloss)
plt.subplot(3,1,2)
plt.plot(t,testloss,'r')
plt.subplot(3,1,3)
plt.plot(t,trainloss,t,testloss,'r')


plt.show()

t = np.arange(0, epoch, 1)
plt.plot(t, trainloss, marker='.', c= 'r', label = "train-set loss")
plt.plot(t, testloss, marker='.', label = "test-set loss")
plt.legend(loc='upper right')
plt.grid()
plt.xlabel('epoch')
plt.ylabel('cross entropy loss')
plt.show()

"""## TEST PART"""

# test
testcount = 0
matrix = np.zeros((10,10))
topthree = np.zeros((10,3))
topthreeimg = [[0,0,0] for _ in range(10)]
print(topthreeimg[0][1])
for testimage, testlabel in testdata:
    img = histogram(testimage.reshape(1,28,28))
    NeuralNet.test(img, testlabel, matrix, topthree,topthreeimg)
    sm = NeuralNet.forward(img, dropout=0)
    if np.argmax(sm) == np.argmax(testlabel):
        testcount += 1
        # print(corcount/wrongcount)

"""## Statics"""

# accuracy
print(testcount)
print(testsize)
print(testcount / testsize)
 
fig, ax = plt.subplots(1,1)

#plt.legend(loc='lower right')
matrix=matrix.T
row = (0,1,2,3,4,5,6,7,8,9)
col = (0,1,2,3,4,5,6,7,8,9)
confu(matrix)
matrix=matrix.T
matrix =  np.round(matrix, 2)
ax.axis('tight')
ax.axis('off')
table = ax.table(cellText=matrix, rowLabels = row, colLabels = col, loc= "center", fontsize=30, colWidths =[0.1]*10)
table.scale(1,3)
plt.xlabel('Label')
plt.ylabel('Predictions')
plt.show()

fig = plt.subplots(10,3)
for i in range(10):
  for j in range(3):
    plt.axis('off')
    plt.subplot(10,3,3*i+j+1)
    plt.imshow(topthreeimg[i][j].reshape(28,28))
print(topthree)